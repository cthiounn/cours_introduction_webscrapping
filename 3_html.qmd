---
title: "Bases pour le Webscraping"
author: "cthiounn"
date: "2024-06-06"
format: html
---

## Comprendre les technologies d'Internet

Pour faire du Webscraping, il est primordiable de comprendre les bases du Web.
Il s'agit de comprendre les manières d'interagir avec les sites et API, avec notamment le [protocole/langage HTTP](https://fr.wikipedia.org/wiki/Hypertext_Transfer_Protocol).
et de connaître les formats de données ([HTML](https://fr.wikipedia.org/wiki/Hypertext_Markup_Language), XML, formats de fichiers, etc)

## Naviguer sur le Web

Pour naviguer sur le Web, notre internaute Lambda utilise son navigateur Web préférée (Edge, Chrome, Mozilla, Opéra, etc.) en tapant le nom du site dans la barre de navigation (1).
Le navigateur affiche la page d'accueil (2). Lambda clique sur un lien (3) et le navigateur lui affiche la nouvelle page (4).

Décortiquons ce qui s'est passé (en omettant des parties techniques comme DNS, les IP et le routage des informations) :

(1) En tapant le nom du site, Lambda dit à son navigateur qu'il souhaite accèder au site (admettons www.insee.fr/) . Le navigateur utilise le langage HTTP au serveur de l'Insee pour demander la page d'accueil, le navigateur envoie la demande "GET /"
(2) Le serveur de l'Insee répond avec la page HTML d'accueil. Le navigateur affiche à l'utilisateur Lambda la page HTML (qui est juste une suite de caractères comprennant des informations entre des balises standardisées <html><header></header><body></body></html>)
(3) Lambda clique sur un lien (e.g. \<a href="/concours/"> Ma page Concours</a>), le navigateur comprends qu'il doit refaire une requête HTTP "GET /concours/"
(4) Le serveur lui répond avec une nouvelle page HTML. (et ainsi de suite...)

## Les URL/URI en pratique

Les [URL](https://fr.wikipedia.org/wiki/Uniform_Resource_Locator) et les [URI](https://fr.wikipedia.org/wiki/Uniform_Resource_Identifier) sont des chaînes de caractères permettant notamment la navigation We (grosso modo ce que vous voyez dans votre barre de navigation en haut de votre navigateur préféré) mais aussi tout échange par Internet, de fichiers et autres informations. Il est important de les observer, de connaître la règle de base suivante :


> URI = protocole + :// +  [utilisateur @] + "nom de domaine" +  [ : port] + requête souhaitée


Exemple :

> https://www.insee.fr/

> protocole : https

> "nom de domaine" : www.insee.fr

> utilisateur : pas d'utilisateur 

> port : 443 (implicite, port par défaut du procole HTTPS)

> requête souhaitée : `/`


Bien souvent, quand vous tapez dans votre navigateur un site, vous faîtes preuve de concision en tapant seulement www.insee.fr. Dès lors, le navigateur est configuré pour naviguer en HTTPS (et mettre le port par défaut, 443 pour HTTPS et 80 pour HTTP) et donc autocomplète le protocole et va par défaut demander la racine `/`

Pour en savoir plus (ressource en anglais) : [Documentation RFC3968](https://www.rfc-editor.org/rfc/rfc3986#section-3)

## Le protocole HTTP(S) et API

Pour interagir avec un site Web (serveur HTTP), il y a un certain nombre de commandes que nous pouvons lui soumettre, aussi appelée [verbe HTTP](https://fr.wikipedia.org/wiki/Hypertext_Transfer_Protocol#M%C3%A9thodes). Voici les plus fréquents :

* **GET** (=récupérer une information, en général une page HTML ou un fichier)
* **POST** (=soumettre de la donnée et récupérer éventuellement une information, obligatoirement le cas dans un formulaire sensible)

Dans le cas des API, si vous avez les droits sur l'API :

* **PUT** (=mettre à jour une information)
* **DELETE** (=supprimer une information)

Pour le Webscraping, nous allons principalement soumettre des requêtes GET et POST (tout comme dans la navigation Web classique)

Le [protocole HTTPS](https://fr.wikipedia.org/wiki/Hypertext_Transfer_Protocol_Secure) (SSL en plus de HTTP) est juste l'ajout d'un chiffrement de toutes les communications, notamment obligatoire si vous soumettez un mot de passe ou une information sensible.
Sans le chiffrement, tout est public et visible à qui se donne la peine de vouloir espionner.
Voyez le chiffrement comme les vitres teintées d'un moyen de locomotion entre deux sites sensibles, dans un bon film d'espionnage !

Les différents sites sont navigables à travers des pages HTML (section suivante) ou renvoient des informations par des API, service renvoyant de la donnée à qui sait la manipuler.

## La page HTML

Pour la navigation Web classique, l'information renvoyée par le serveur est structurée au format [HTML](https://fr.wikipedia.org/wiki/Hypertext_Markup_Language) : il y a notamment un titre principal et un contenu hierarchisé.
Le serveur renvoie un ensemble de caractères toujours structurée de la même façon de manière macro :

* balise \<html> \</html> pour délimiter tout le périmètre
* à l'intérieur, redecoupage en balise \<head>\</head> || \<body>\</body>
* les données intéressantes sont généralement dans le body (corps du contenu)
* dans le corps du contenu \<body>, utilisation d'un vocabulaire de balise 

Exemples de balises les plus fréquentes :

* \<p> : paragraphe
* \<h1> \<h2> ... : titre 
* \<a> : lien HTTP 
* \<div> : bloc de contenu (pas de signification sémantique, utilisé pour les scripts ou le CSS)
* \<section> : ensemble de contenu (signification sémantique, comme un chapitre d'un livre)
* \<button> : bouton
* \<form> : formulaire

Cette structuration permet de questionner la page (est-ce qu'il y a des liens HTTP présents sur la page ? si oui, renvoie les moi) et récupérer les informations associées.

## Au delà de HTML : CSS et JavaScript

La librairie [CSS](https://fr.wikipedia.org/wiki/Feuilles_de_style_en_cascade) permet d'habiller le site de couleur et de mieux agencer l'information. Le CSS n'est pas utile pour le Webscraping mais seulement agréable à l'oeil des internautes.
Cependant, les scripts [JavaScript](https://fr.wikipedia.org/wiki/JavaScript) permettent d'ajouter du dynamisme au site, en rajoutant des effets conditionnels, de charger les données a posteriori.
Le chargement de données a posteriori par des JavaScript va complexifier les méthodes utilisées pour le Webscraping.